# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1853Tb1b9AwfuUSFqV4fDT9bpe6kpRs_C
"""

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout
from tensorflow.keras.models import Model

(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.fashion_mnist.load_data()
print(X_train.shape)

(xtrain,ytrain), (xtest,ytest) = tf.keras.datasets.cifar10.load_data()
print(xtrain.shape)

(dxtrain,dytrain), (dxtest,dytest) = tf.keras.datasets.cifar100.load_data()
print(xtrain.shape)

def adjustPixels(trainData, testData):
  trainData = trainData/255.0
  testData = testData/255.0

  return trainData,testData

X_train,X_test = adjustPixels(X_train, X_test)

xtrain,xtest = adjustPixels(xtrain,xtest)
dxtrain,dxtest = adjustPixels(dxtrain,dxtest)

#This cell checks which training dataset needs dimension expansion
print(X_train.shape)
print(xtrain.shape)
print(dxtrain.shape)
#Evidently X_train consists of Grayscale images and CNN accepts a channel input hence expanding the input dimension by 1

#Expanding the dimensions of X_train, X_test by 1
X_train = np.expand_dims(X_train, -1)
X_test = np.expand_dims(X_test, -1)

k = len(set(Y_train))
print(k)

#Building the model 
i = Input(shape = X_train[0].shape)
x = Conv2D(32,(3,3), strides = 2, activation = 'relu')(i)
x = Conv2D(64, (3,3), strides = 2, activation = 'relu')(x)
x = Conv2D(128, (3,3), strides = 2, activation = 'relu')(x)
x = Flatten()(x)
x = Dense(256, activation = 'relu')(x)
x = Dropout(0.2)(x)
x = Dense(k, activation = 'softmax')(x)

model = Model(i,x)

model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])
r = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 19)

plt.plot(r.history['loss'], label = 'loss')
plt.plot(r.history['accuracy'], label = 'accuracy')
plt.show()

ytrain, ytest = ytrain.flatten(), ytest.flatten()

kS = len(set(ytrain))
print(kS)

#Building the model 

i = Input(shape = xtrain[0].shape)
x = Conv2D(64,(3,3), strides = 2, activation = 'relu')(i)
x = Conv2D(128, (3,3), strides = 2, activation = 'relu')(x)
x = Conv2D(256, (3,3), strides = 2, activation = 'relu')(x)
x = Flatten()(x)
x = Dense(512, activation = 'relu')(x)
x = Dropout(0.2)(x)
x = Dense(kS, activation = 'softmax')(x)

model = Model(i,x)

model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

r2 = model.fit(xtrain,ytrain, validation_data = (xtest,ytest), epochs = 15)

#Building the model 

kT = len(set(dytrain.flatten()))
i = Input(shape = dxtrain[0].shape)
x = Conv2D(64,(3,3), strides = 2, activation = 'relu')(i)
x = Conv2D(128, (3,3), strides = 2, activation = 'relu')(x)
x = Conv2D(256, (3,3), strides = 2, activation = 'relu')(x)
x = Flatten()(x)
x = Dense(512, activation = 'relu')(x)
x = Dropout(0.2)(x)
x = Dense(kT, activation = 'softmax')(x)

model = Model(i,x)

model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

r3 = model.fit(dxtrain,dytrain, validation_data = (dxtest,dytest), epochs = 10)

